{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7b89d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/hpaceice1/vkondepudi3/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#including all the necessary libraries\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n",
    "import cv2\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11220acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing the transform\n",
    "LABELS_Severity = {35: 0,\n",
    "                   43: 0,\n",
    "                   47: 1,\n",
    "                   53: 1,\n",
    "                   61: 2,\n",
    "                   65: 2,\n",
    "                   71: 2,\n",
    "                   85: 2}\n",
    "\n",
    "\n",
    "mean = (.1706)\n",
    "std = (.2112)\n",
    "normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size=(224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e2b7b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCTDataset(Dataset):\n",
    "    def __init__(self, args, subset='train', transform=None,):\n",
    "        if subset == 'train':\n",
    "            self.annot = pd.read_csv(args.annot_train_prime)\n",
    "        elif subset == 'test':\n",
    "            self.annot = pd.read_csv(args.annot_test_prime)\n",
    "            \n",
    "        self.annot['Severity_Label'] = [LABELS_Severity[drss] for drss in copy.deepcopy(self.annot['DRSS'].values)] \n",
    "        # print(self.annot)\n",
    "        self.root = os.path.expanduser(args.data_root)\n",
    "        self.transform = transform\n",
    "        # self.subset = subset\n",
    "        self.nb_classes=len(np.unique(list(LABELS_Severity.values())))\n",
    "        self.path_list = self.annot['File_Path'].values\n",
    "        self._labels = self.annot['Severity_Label'].values\n",
    "        assert len(self.path_list) == len(self._labels)\n",
    "        # idx_each_class = [[] for i in range(self.nb_classes)]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = Image.open(self.root+self.path_list[index]).convert(\"L\"), self._labels[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._labels)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a112a4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NotebookArgs:\n",
    "    def __init__(self, annot_train_prime = 'df_prime_train.csv', annot_test_prime = 'df_prime_test.csv', data_root = '/storage/home/hpaceice1/shared-classes/materials/ece8803fml/'):\n",
    "        self.annot_train_prime = annot_train_prime\n",
    "        self.annot_test_prime = annot_test_prime\n",
    "        self.data_root = data_root\n",
    "args = NotebookArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67a2d503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the data \n",
    "trainset = OCTDataset(args, 'train', transform=transform)\n",
    "testset = OCTDataset(args, 'test', transform=transform)\n",
    "\n",
    "# Define hyperparameters\n",
    "batch_size = 32\n",
    "num_epochs = 1\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fc4739c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_X_y_from_loader(loader):\n",
    "    X, y = [], []\n",
    "    for sample in tqdm(loader, total=len(loader)):\n",
    "        images, labels = sample[0], sample[1]\n",
    "        X.extend([a.numpy().flatten() for a in images])\n",
    "        y.extend([a.numpy().flatten() for a in labels])\n",
    "        break\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69d9d60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/758 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_X_y_from_loader(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6706f1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50176,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dc29d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [01:13<00:00, 10.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def get_X_y_from_loader(loader):\n",
    "    X, y = [], []\n",
    "    #i=0\n",
    "    for sample in tqdm(loader, total=len(loader)):\n",
    "        #i = i+1\n",
    "        images, labels = sample[0], sample[1]\n",
    "        X.extend([a.numpy()[0] for a in images])\n",
    "        y.extend([a.numpy().flatten() for a in labels])\n",
    "        #break\n",
    "        #if(i == 10):\n",
    "         #   break\n",
    "    return X,y\n",
    "X_train, y_train = get_X_y_from_loader(train_loader)\n",
    "print(len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a58a5b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24252/24252 [09:12<00:00, 43.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5832,)\n",
      "24252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_hog = []\n",
    "for i in tqdm(range(len(X_train))):\n",
    "    #X_hog = X_train[i].reshape((224,224))\n",
    "    hog_features = hog(X_train[i], pixels_per_cell=(8, 8),\n",
    "                              cells_per_block=(2, 2), orientations=2, block_norm='L2-Hys',\n",
    "                              feature_vector=True)\n",
    "    X_train_hog.append(hog_features)\n",
    "print(X_train_hog[0].shape)\n",
    "print(len(X_train_hog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eccf4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'from sklearn.linear_model import LogisticRegression\\nfrom sklearn.model_selection import GridSearchCV\\n\\n# Define the hyperparameter grid\\nhyperparameters = { \\'penalty\\': [\\'l1\\', \\'l2\\'],\\n    \\'C\\': [0.001, 0.01, 0.1, 1, 10, 100],\\n    \\'solver\\': [\\'liblinear\\', \\'newton-cg\\', \\'lbfgs\\', \\'sag\\', \\'saga\\'],\\n    \\'class_weight\\': [None, \\'balanced\\']}\\n\\n# Define the logistic regression model\\nmodel = LogisticRegression(max_iter=500)\\n\\n# Define the grid search object\\ngrid_search = GridSearchCV(model, hyperparameters, cv=5, scoring=\\'accuracy\\')\\n\\nX_train_grid = X_train_hog[0:1000]\\ny_train_grid = y_train[0:1000]\\ny_train_grid  = np.ravel(y_train_grid)\\n# Fit the grid search object on the training data\\ngrid_search.fit(X_train_grid, y_train_grid)\\n\\n# Get the best hyperparameters\\nbest_params = grid_search.best_params_\\n\\n\\n# Print the best hyperparameters and their corresponding score\\nprint(\"Best hyperparameters: \", grid_search.best_params_)\\nprint(\"Best score: \", grid_search.best_score_)\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#performing grid search\n",
    "'''from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the hyperparameter grid\n",
    "hyperparameters = { 'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "    'class_weight': [None, 'balanced']}\n",
    "\n",
    "# Define the logistic regression model\n",
    "model = LogisticRegression(max_iter=500)\n",
    "\n",
    "# Define the grid search object\n",
    "grid_search = GridSearchCV(model, hyperparameters, cv=5, scoring='accuracy')\n",
    "\n",
    "X_train_grid = X_train_hog[0:1000]\n",
    "y_train_grid = y_train[0:1000]\n",
    "y_train_grid  = np.ravel(y_train_grid)\n",
    "# Fit the grid search object on the training data\n",
    "grid_search.fit(X_train_grid, y_train_grid)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "\n",
    "# Print the best hyperparameters and their corresponding score\n",
    "print(\"Best hyperparameters: \", grid_search.best_params_)\n",
    "print(\"Best score: \", grid_search.best_score_)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "571557b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24252\n",
      "24252\n"
     ]
    }
   ],
   "source": [
    "print(len(y_train))\n",
    "X_subset = X_train_hog\n",
    "y_subset = y_train\n",
    "print(len(X_subset ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "68b58944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/hpaceice1/vkondepudi3/.local/lib/python3.9/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/storage/home/hpaceice1/vkondepudi3/.local/lib/python3.9/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, class_weight=&#x27;balanced&#x27;, multi_class=&#x27;ovr&#x27;,\n",
       "                   solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, class_weight=&#x27;balanced&#x27;, multi_class=&#x27;ovr&#x27;,\n",
       "                   solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10, class_weight='balanced', multi_class='ovr',\n",
       "                   solver='liblinear')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the logistic regression model\n",
    "lr_model = LogisticRegression(C=10, class_weight='balanced', penalty='l2', solver='liblinear', multi_class='ovr')\n",
    "\n",
    "# Fit the model to the training data\n",
    "lr_model.fit(X_subset, y_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "501ac382",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [04:17<00:00,  1.03s/it]\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = get_X_y_from_loader(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08702016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7987/7987 [03:00<00:00, 44.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5832,)\n",
      "7987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_hog = []\n",
    "for i in tqdm(range(len(X_test))):\n",
    "    #X_hog = X_train[i].reshape((224,224))\n",
    "    hog_features = hog(X_test[i], pixels_per_cell=(8, 8),\n",
    "                              cells_per_block=(2, 2), orientations=2, block_norm='L2-Hys',\n",
    "                              feature_vector=True)\n",
    "    X_test_hog.append(hog_features)\n",
    "print(X_test_hog[0].shape)\n",
    "print(len(X_test_hog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "61bd0824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4735194691373482\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# Make predictions on the testing data\n",
    "y_pred = lr_model.predict(X_test_hog)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cb96801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced accuracy score: 0.41082970409007274\n",
      "Precision score: 0.45744061268156644\n",
      "Recall score: 0.4735194691373482\n",
      "F1 score weighted: 0.4622126660936432\n",
      "F1 score Micro: 0.4735194691373482\n",
      "F1 score Macro: 0.41225010506483506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate balanced accuracy score\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "print(\"Balanced accuracy score:\", balanced_acc)\n",
    "\n",
    "# Calculate precision score\n",
    "precision = precision_score(y_test, y_pred,average='weighted')\n",
    "print(\"Precision score:\", precision)\n",
    "\n",
    "# Calculate recall score\n",
    "recall = recall_score(y_test, y_pred,average='weighted')\n",
    "print(\"Recall score:\", recall)\n",
    "\n",
    "# Calculate f1 score\n",
    "f1 = f1_score(y_test, y_pred,average='weighted')\n",
    "print(\"F1 score weighted:\", f1)\n",
    "\n",
    "# Calculate f1 score\n",
    "f1 = f1_score(y_test, y_pred,average='micro')\n",
    "print(\"F1 score Micro:\", f1)\n",
    "\n",
    "# Calculate f1 score\n",
    "f1 = f1_score(y_test, y_pred,average='macro')\n",
    "print(\"F1 score Macro:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc2dec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
