{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a6a0e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/hpaceice1/vkondepudi3/.local/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import cv2\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9649cd36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing transformation\n",
    "LABELS_Severity = {35: 0,\n",
    "                   43: 0,\n",
    "                   47: 1,\n",
    "                   53: 1,\n",
    "                   61: 2,\n",
    "                   65: 2,\n",
    "                   71: 2,\n",
    "                   85: 2}\n",
    "\n",
    "\n",
    "mean = (.1706)\n",
    "std = (.2112)\n",
    "normalize = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(size=(224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    lambda x : x.expand(3,*x.shape[1:]),\n",
    "    normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b805e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OCTDataset(Dataset):\n",
    "    def __init__(self, args, subset='train', transform=None,):\n",
    "        if subset == 'train':\n",
    "            self.annot = pd.read_csv(args.annot_train_prime)\n",
    "        elif subset == 'test':\n",
    "            self.annot = pd.read_csv(args.annot_test_prime)\n",
    "            \n",
    "        self.annot['Severity_Label'] = [LABELS_Severity[drss] for drss in copy.deepcopy(self.annot['DRSS'].values)] \n",
    "        # print(self.annot)\n",
    "        self.root = os.path.expanduser(args.data_root)\n",
    "        self.transform = transform\n",
    "        # self.subset = subset\n",
    "        self.nb_classes=len(np.unique(list(LABELS_Severity.values())))\n",
    "        self.path_list = self.annot['File_Path'].values\n",
    "        self._labels = self.annot['Severity_Label'].values\n",
    "        assert len(self.path_list) == len(self._labels)\n",
    "        # idx_each_class = [[] for i in range(self.nb_classes)]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = Image.open(self.root+self.path_list[index]).convert(\"L\"), self._labels[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._labels)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "491381a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a class to load all the required data\n",
    "class NotebookArgs:\n",
    "    def __init__(self, annot_train_prime = 'df_prime_train.csv', annot_test_prime = 'df_prime_test.csv', data_root = '/storage/home/hpaceice1/shared-classes/materials/ece8803fml/'):\n",
    "        self.annot_train_prime = annot_train_prime\n",
    "        self.annot_test_prime = annot_test_prime\n",
    "        self.data_root = data_root\n",
    "args = NotebookArgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5338b44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the test and train set\n",
    "trainset = OCTDataset(args, 'train', transform=transform)\n",
    "testset = OCTDataset(args, 'test', transform=transform)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad93dc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading images and labels from the loader\n",
    "def get_X_y_from_loader(loader):\n",
    "    X, y = [], []\n",
    "    for sample in tqdm(loader, total=len(loader)):\n",
    "        images, labels = sample[0], sample[1]\n",
    "        X.extend([a.numpy()[0] for a in images])\n",
    "        y.extend([a.numpy().flatten() for a in labels])\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92f364d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 758/758 [01:19<00:00,  9.54it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = get_X_y_from_loader(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2391118f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 24252/24252 [09:10<00:00, 44.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5832,)\n",
      "24252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Applying HOG feature extractor on the images\n",
    "X_train_hog = []\n",
    "for i in tqdm(range(len(X_train))):\n",
    "    hog_features = hog(X_train[i], pixels_per_cell=(8, 8),\n",
    "                              cells_per_block=(2, 2), orientations=2, block_norm='L2-Hys',\n",
    "                              feature_vector=True)\n",
    "    X_train_hog.append(hog_features)\n",
    "print(X_train_hog[0].shape)\n",
    "print(len(X_train_hog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82d74641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:25<00:00,  9.65it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = get_X_y_from_loader(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1700a2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24252\n"
     ]
    }
   ],
   "source": [
    "X_subset = X_train_hog\n",
    "y_subset = y_train\n",
    "y_subset = [i[0] for i in y_subset]\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb2d0915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7987/7987 [03:01<00:00, 44.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5832,)\n",
      "7987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "X_test_hog = []\n",
    "for i in tqdm(range(len(X_test))):\n",
    "    #X_hog = X_train[i].reshape((224,224))\n",
    "    hog_features = hog(X_test[i], pixels_per_cell=(8, 8),\n",
    "                              cells_per_block=(2, 2), orientations=2, block_norm='L2-Hys',\n",
    "                              feature_vector=True)\n",
    "    X_test_hog.append(hog_features)\n",
    "print(X_test_hog[0].shape)\n",
    "print(len(X_test_hog))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "67f57f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [i[0] for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "158517cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/11717.sched-pace-ice.pace.gatech.edu/ipykernel_170985/238174777.py:13: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646756402876/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  X_train_tensor = torch.Tensor(X_subset)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 1.0046941041946411\n",
      "Epoch: 2 Loss: 1.0673706531524658\n",
      "Epoch: 3 Loss: 1.0759786367416382\n",
      "Epoch: 4 Loss: 1.034498929977417\n",
      "Epoch: 5 Loss: 0.9557835459709167\n",
      "Epoch: 6 Loss: 0.9149312376976013\n",
      "Epoch: 7 Loss: 1.0358635187149048\n",
      "Epoch: 8 Loss: 1.0407699346542358\n",
      "Epoch: 9 Loss: 1.0144894123077393\n",
      "Epoch: 10 Loss: 1.0372117757797241\n",
      "Test accuracy: 0.4464755227244272\n"
     ]
    }
   ],
   "source": [
    "#applying feed forward network\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Define the number of input features\n",
    "input_dim = len(X_subset[0])\n",
    "\n",
    "# Define the number of output classes\n",
    "num_classes = 3\n",
    "\n",
    "# Convert the training and test sets to PyTorch tensors\n",
    "X_train_tensor = torch.Tensor(X_subset)\n",
    "y_train_tensor = torch.LongTensor(y_subset)\n",
    "X_test_tensor = torch.Tensor(X_test_hog)\n",
    "y_test_tensor = torch.LongTensor(y_test)\n",
    "\n",
    "# Define the model architecture\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_dim, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024,512),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(512,256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256,128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128,64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64,32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32,16),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(16, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, num_classes),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# Define the training data loader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('Epoch:', epoch+1, 'Loss:', loss.item())\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "with torch.no_grad():\n",
    "    output = model(X_test_tensor)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    accuracy = (predicted == y_test_tensor).sum().item() / len(y_test)\n",
    "    print('Test accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b566087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy on 7987 points is 0.4464755227244272\n",
      "f1 score on 7987 points is 0.4003987378161625\n",
      "Test precision on 7987 points is 0.3629972810573795\n",
      "Test recall on 7987 points is 0.4464755227244272\n",
      "Test balanced accuracy on 7987 points is 0.3528649921507065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/hpaceice1/vkondepudi3/.local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#printing all the required output\n",
    "from sklearn.metrics import precision_score, recall_score, balanced_accuracy_score,f1_score\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(X_test_tensor)\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    predicted = predicted.cpu()\n",
    "    accuracy = (predicted == y_test_tensor).sum().item() / len(y_test_tensor)\n",
    "    print(f'Test accuracy on {len(predicted)} points is {accuracy}')\n",
    "    f1 = f1_score(y_test_tensor.cpu().numpy(), predicted.numpy(), average='weighted')\n",
    "    precision = precision_score(y_test_tensor.cpu().numpy(), predicted.numpy(), average='weighted')\n",
    "    recall = recall_score(y_test_tensor.cpu().numpy(), predicted.numpy(), average='weighted')\n",
    "    balanced_accuracy = balanced_accuracy_score(y_test_tensor.cpu().numpy(), predicted.numpy())\n",
    "    print(f'f1 score on {len(predicted)} points is {f1}')\n",
    "    print(f'Test precision on {len(predicted)} points is {precision}')\n",
    "    print(f'Test recall on {len(predicted)} points is {recall}')\n",
    "    print(f'Test balanced accuracy on {len(predicted)} points is {balanced_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff966b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
